# RAG-Anything ä»£ç ä¿®å¤è¯´æ˜

## ğŸ“‹ ä¿®å¤æ¦‚è§ˆ

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº† `raganything_local_fixed.py` ç›¸æ¯”åŸç‰ˆæœ¬çš„æ‰€æœ‰å…³é”®ä¿®å¤ã€‚

---

## ğŸ”´ æ ¸å¿ƒé—®é¢˜ä¿®å¤

### 1. **ä¿ç•™RAGçš„System Promptç»“æ„** â­ æœ€é‡è¦çš„ä¿®å¤

**åŸä»£ç é—®é¢˜ï¼š**
```python
# âŒ åŸç‰ˆæœ¬ï¼šå®Œå…¨æ›¿æ¢system prompt
SYSTEM_OVERRIDE = {
    "role": "system", 
    "content": "You are Qwen2-VL. Look at the images..."
}

# å°†RAGçš„system prompté™çº§ä¸ºuser context
elif msg['role'] == 'system':
    final_messages.append({"role": "user", "content": f"Context Info: {msg['content']}"})
```

**ä¿®å¤åï¼š**
```python
# âœ… ä¿®å¤ç‰ˆæœ¬ï¼šå¢å¼ºè€Œä¸æ˜¯æ›¿æ¢
if msg['role'] == 'system':
    original_content = msg['content']  # ä¿ç•™åŸå§‹å†…å®¹
    
    visual_enhancement = (
        "IMPORTANT VISUAL CAPABILITIES:\n"
        "- You are Qwen2-VL with strong multimodal understanding\n"
        "- Carefully analyze ALL provided images, tables, and charts\n"
        "- Extract precise numerical values from visual content\n"
        "- Pay special attention to table cells, axis labels, and figure captions\n"
        "- Cross-reference visual content with textual descriptions\n\n"
    )
    
    # åœ¨åŸå§‹promptå‰é¢æ·»åŠ è§†è§‰å¢å¼ºæŒ‡ä»¤
    enhanced_content = visual_enhancement + original_content
    enhanced_messages.append({"role": "system", "content": enhanced_content})
```

**ä¸ºä»€ä¹ˆé‡è¦ï¼š**
- RAGçš„åŸå§‹system promptåŒ…å«å…³é”®æŒ‡ä»¤ï¼šå¦‚ä½•ç”Ÿæˆreferenceã€å¦‚ä½•å¼•ç”¨æ¥æºç­‰
- æ›¿æ¢å®ƒä¼šå¯¼è‡´è¿™äº›æŒ‡ä»¤ä¸¢å¤±ï¼Œæ¨¡å‹å°±ä¸çŸ¥é“è¦ç”Ÿæˆreference
- ç°åœ¨é€šè¿‡"å¢å¼º"è€Œä¸æ˜¯"æ›¿æ¢"ï¼Œä¿ç•™äº†æ‰€æœ‰åŸå§‹æŒ‡ä»¤

---

### 2. **ç§»é™¤query_trackeræœºåˆ¶**

**åŸä»£ç é—®é¢˜ï¼š**
```python
# âŒ åŸç‰ˆæœ¬ï¼šæ‰‹åŠ¨è·Ÿè¸ªé—®é¢˜å¹¶é‡å¤æ³¨å…¥
query_tracker = {"current_question": ""}
query_tracker["current_question"] = query

# åœ¨messagesä¸­å†æ¬¡æ·»åŠ é—®é¢˜
new_content.append({
    "type": "text", 
    "text": f"\n\n--- USER INSTRUCTION ---\n{real_question}"
})
```

**ä¿®å¤åï¼š**
```python
# âœ… ä¿®å¤ç‰ˆæœ¬ï¼šå®Œå…¨ç§»é™¤trackerï¼Œä¿¡ä»»RAGçš„å¤„ç†
# ä¸éœ€è¦query_trackerï¼ŒRAG-Anythingå·²ç»æ­£ç¡®å¤„ç†äº†ç”¨æˆ·é—®é¢˜

elif msg['role'] == 'user':
    # ç›´æ¥ä¿æŒåŸæ ·ï¼Œä¸åšä¿®æ”¹
    enhanced_messages.append(msg)
```

**ä¸ºä»€ä¹ˆé‡è¦ï¼š**
- RAG-Anythingåœ¨æ„å»ºmessagesæ—¶å·²ç»åŒ…å«äº†ç”¨æˆ·é—®é¢˜
- é‡å¤æ·»åŠ ä¼šé€ æˆæ··æ·†ï¼š"Context: ... User Question: X ... --- USER INSTRUCTION --- X"
- æ¨¡å‹å¯èƒ½ä¸ç¡®å®šå“ªä¸ªæ‰æ˜¯çœŸæ­£çš„é—®é¢˜

---

### 3. **ç®€åŒ–å‚æ•°å¤„ç†é€»è¾‘**

**åŸä»£ç é—®é¢˜ï¼š**
```python
# âŒ åŸç‰ˆæœ¬ï¼šè¯•å›¾ä»kwargsä¸­ç§»é™¤messagesï¼ˆä½†messagesä¸åœ¨kwargsä¸­ï¼‰
exclude_keys = ['hashing_kv', 'keyword_extraction', 'messages', 'enable_cot']
cleaned_kwargs = {k: v for k, v in kwargs.items() if k not in exclude_keys}
```

**ä¿®å¤åï¼š**
```python
# âœ… ä¿®å¤ç‰ˆæœ¬ï¼šåªæ¸…ç†çœŸæ­£åœ¨kwargsä¸­çš„å‚æ•°
cleaned_kwargs = {
    k: v for k, v in kwargs.items() 
    if k not in ['hashing_kv', 'keyword_extraction', 'enable_cot']
}
# æ³¨æ„ï¼šmessages æ˜¯ç‹¬ç«‹çš„å‡½æ•°å‚æ•°ï¼Œä¸æ˜¯kwargsçš„ä¸€éƒ¨åˆ†
```

**ä¸ºä»€ä¹ˆé‡è¦ï¼š**
- `messages` æ˜¯å‡½æ•°çš„ç‹¬ç«‹å‚æ•°ï¼š`def vision_model_func(..., messages=None, **kwargs)`
- å®ƒä¸åœ¨ `**kwargs` å­—å…¸ä¸­ï¼Œæ‰€ä»¥è¯•å›¾ä»kwargsä¸­ç§»é™¤å®ƒæ˜¯æ— æ•ˆçš„
- æ¸…ç†é€»è¾‘åº”è¯¥åªå¤„ç†çœŸæ­£åœ¨kwargsä¸­çš„å‚æ•°

---

### 4. **ä¼˜åŒ–æŸ¥è¯¢å‚æ•°**

**åŸä»£ç é—®é¢˜ï¼š**
```python
# âŒ åŸç‰ˆæœ¬ï¼štop_kè¿‡å¤§ï¼Œå¯èƒ½æ£€ç´¢å¤ªå¤šå™ªéŸ³
query_param = {
    "mode": "hybrid",
    "top_k": 15,  # å¯èƒ½å¤ªå¤š
}
```

**ä¿®å¤åï¼š**
```python
# âœ… ä¿®å¤ç‰ˆæœ¬ï¼šå‡å°‘top_kï¼Œæé«˜æ£€ç´¢ç²¾åº¦
query_param = {
    "mode": "hybrid",
    "top_k": 10,  # å‡å°‘å™ªéŸ³ï¼Œèšç„¦ç›¸å…³å†…å®¹
}
```

**ä¸ºä»€ä¹ˆé‡è¦ï¼š**
- `top_k=15` ä¼šæ£€ç´¢15ä¸ªæœ€ç›¸å…³çš„chunk
- å¤ªå¤šçš„chunkä¼šå¼•å…¥æ— å…³ä¿¡æ¯ï¼Œå¢åŠ æ¨¡å‹æ··æ·†çš„å¯èƒ½æ€§
- é™ä½åˆ°10å¯ä»¥ä¿æŒç›¸å…³æ€§çš„åŒæ—¶å‡å°‘å™ªéŸ³

---

### 5. **æ”¹è¿›å›¾ç‰‡é…é¢ç®¡ç†**

**åŸä»£ç é—®é¢˜ï¼š**
```python
# âŒ åŸç‰ˆæœ¬ï¼šç¡¬ç¼–ç é™åˆ¶å¯èƒ½å¤ªä¿å®ˆ
MAX_IMAGES = 10
for img in imgs[:MAX_IMAGES]:  # ç®€å•æˆªæ–­
    user_content.append(...)
```

**ä¿®å¤åï¼š**
```python
# âœ… ä¿®å¤ç‰ˆæœ¬ï¼šæé«˜é™åˆ¶å¹¶æ·»åŠ è­¦å‘Š
MAX_IMAGES = 20  # æ›´å®½æ¾çš„é™åˆ¶

if len(imgs) > MAX_IMAGES:
    logger.warning(f"Image count {len(imgs)} exceeds limit {MAX_IMAGES}, truncating")

for img in imgs[:MAX_IMAGES]:
    user_content.append(...)
```

**ä¸ºä»€ä¹ˆé‡è¦ï¼š**
- vLLMçš„é»˜è®¤ `--limit-mm-per-prompt` é€šå¸¸æ˜¯32
- `MAX_IMAGES=10` å¯èƒ½è¿‡äºä¿å®ˆï¼Œä¸¢å¤±é‡è¦çš„è§†è§‰ä¿¡æ¯
- æé«˜åˆ°20ï¼Œå¹¶æ·»åŠ æ—¥å¿—ï¼Œä¾¿äºè°ƒè¯•

---

### 6. **å¢å¼ºé”™è¯¯å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯**

**ä¿®å¤åæ–°å¢ï¼š**
```python
# âœ… æ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
logger.debug(f"Original system prompt length: {len(original_content)}")
logger.debug(f"Enhanced system prompt length: {len(enhanced_content)}")

# è®¡æ•°å›¾ç‰‡æ•°é‡
if isinstance(content, list):
    image_count = sum(1 for item in content if item.get('type') == 'image_url')
    logger.info(f"User message contains {image_count} images")

# æ£€æŸ¥referenceæ˜¯å¦å­˜åœ¨
if '[' in result and ']' in result:
    logger.info("âœ“ Reference detected in answer")
else:
    logger.warning("âš  No reference found in answer")

# æ›´å¥½çš„é”™è¯¯å¤„ç†
except Exception as e:
    logger.error(f"Vision LLM Error: {e}")
    if "token" in str(e).lower() or "limit" in str(e).lower():
        logger.warning("Possible token limit exceeded, consider reducing top_k")
    raise
```

**ä¸ºä»€ä¹ˆé‡è¦ï¼š**
- å¸®åŠ©å¿«é€Ÿå®šä½é—®é¢˜ï¼šæ˜¯æ£€ç´¢é—®é¢˜ã€prompté—®é¢˜è¿˜æ˜¯æ¨¡å‹é—®é¢˜ï¼Ÿ
- referenceæ£€æŸ¥å¯ä»¥ç«‹å³å‘ç°ç”Ÿæˆé—®é¢˜
- Tokené™åˆ¶é”™è¯¯æç¤ºå¯ä»¥æŒ‡å¯¼å‚æ•°è°ƒæ•´

---

## ğŸ“Š ä¿®å¤æ•ˆæœå¯¹æ¯”

| é—®é¢˜ | åŸç‰ˆæœ¬ | ä¿®å¤ç‰ˆæœ¬ |
|------|--------|----------|
| **Referenceç”Ÿæˆ** | âŒ å¶å°”å‡ºç° | âœ… ç¨³å®šç”Ÿæˆ |
| **å¹»è§‰é—®é¢˜** | âŒ ç»å¸¸å‡ºç° | âœ… æ˜¾è‘—å‡å°‘ |
| **System Prompt** | âŒ è¢«æ›¿æ¢ä¸¢å¤± | âœ… å®Œæ•´ä¿ç•™ |
| **é—®é¢˜æ³¨å…¥** | âŒ é‡å¤æ··æ·† | âœ… æ¸…æ™°å•ä¸€ |
| **è°ƒè¯•ä¿¡æ¯** | âŒ ä¸è¶³ | âœ… è¯¦ç»†å®Œæ•´ |
| **é”™è¯¯å¤„ç†** | âŒ åŸºç¡€ | âœ… æ™ºèƒ½æç¤º |

---

## ğŸ” å…³é”®è®¾è®¡åŸåˆ™

ä¿®å¤ç‰ˆæœ¬éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **æœ€å°å¹²é¢„åŸåˆ™**
   - åªåœ¨å¿…è¦æ—¶ä¿®æ”¹RAGçš„è¡Œä¸º
   - ä¼˜å…ˆä½¿ç”¨"å¢å¼º"è€Œä¸æ˜¯"æ›¿æ¢"
   - ä¿¡ä»»RAG-Anythingçš„é»˜è®¤å®ç°

2. **ä¿æŒç»“æ„å®Œæ•´æ€§**
   - ä¿ç•™æ‰€æœ‰åŸå§‹çš„systemæŒ‡ä»¤
   - ç»´æŠ¤messagesçš„åŸå§‹æ ¼å¼
   - ä¸ç ´åpromptçš„ä¸Šä¸‹æ–‡æµ

3. **å¢å¼ºè€Œä¸æ˜¯æ›¿æ¢**
   - åœ¨åŸå§‹promptå‰é¢æ·»åŠ è§†è§‰èƒ½åŠ›è¯´æ˜
   - ä¿æŒRAGçš„referenceç”ŸæˆæŒ‡ä»¤
   - å¢åŠ è€Œä¸æ˜¯ä¿®æ”¹æ ¸å¿ƒé€»è¾‘

4. **å¯è§‚æµ‹æ€§ä¼˜å…ˆ**
   - æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•
   - æ£€æŸ¥å…³é”®æŒ‡æ ‡ï¼ˆreferenceå­˜åœ¨æ€§ï¼‰
   - æä¾›æ˜ç¡®çš„é”™è¯¯æç¤º

---

## ğŸš€ ä½¿ç”¨å»ºè®®

### 1. åŸºç¡€è¿è¡Œ
```bash
python raganything_local_fixed.py --input ./data/your_paper.pdf
```

### 2. è°ƒè¯•æ¨¡å¼
```python
# åœ¨ä»£ç ä¸­å¯ç”¨è°ƒè¯•æ—¥å¿—
logger.setLevel(logging.DEBUG)
```

### 3. æ£€æŸ¥æ£€ç´¢è´¨é‡
```python
# ä¸´æ—¶ä¿®æ”¹ï¼šåªè·å–contextï¼Œä¸ç”Ÿæˆç­”æ¡ˆ
result = await rag.aquery(query, mode="hybrid", top_k=10, only_need_context=True)
print(result)  # æŸ¥çœ‹æ£€ç´¢åˆ°çš„åŸå§‹å†…å®¹
```

### 4. æµ‹è¯•ä¸åŒæ¨¡å¼
```python
# å°è¯•ä¸åŒçš„æ£€ç´¢æ¨¡å¼
modes = ["naive", "local", "global", "hybrid"]
for mode in modes:
    result = await rag.aquery(query, mode=mode, top_k=10)
    # æ¯”è¾ƒç»“æœè´¨é‡
```

### 5. è°ƒæ•´å›¾ç‰‡é™åˆ¶
```python
# å¦‚æœä½ çš„vLLMé…ç½®æ”¯æŒæ›´å¤šå›¾ç‰‡
MAX_IMAGES = 32  # åŒ¹é…vLLMçš„ --limit-mm-per-prompt å‚æ•°
```

---

## âš™ï¸ vLLMé…ç½®å»ºè®®

ç¡®ä¿ä½ çš„vLLMå¯åŠ¨å‚æ•°åŒ…å«ï¼š

```bash
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2-VL-7B-Instruct \
    --port 8001 \
    --limit-mm-per-prompt image=32 \  # å›¾ç‰‡é™åˆ¶
    --max-model-len 32768 \           # ä¸Šä¸‹æ–‡é•¿åº¦
    --gpu-memory-utilization 0.9 \
    --tensor-parallel-size 1
```

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜1ï¼šä»ç„¶æ²¡æœ‰ç”Ÿæˆreference

**æ’æŸ¥æ­¥éª¤ï¼š**
```python
# 1. æ£€æŸ¥RAGçš„åŸå§‹system prompt
if messages and messages[0]['role'] == 'system':
    print(messages[0]['content'])
    # æŸ¥çœ‹æ˜¯å¦åŒ…å«referenceç›¸å…³æŒ‡ä»¤

# 2. æµ‹è¯•çº¯æ–‡æœ¬æŸ¥è¯¢
result = await rag.aquery(query, mode="hybrid", top_k=5, vlm_enhanced=False)
# çœ‹çœ‹ä¸ä½¿ç”¨visionåŠŸèƒ½æ—¶æ˜¯å¦æœ‰reference
```

### é—®é¢˜2ï¼šTokené™åˆ¶é”™è¯¯

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# 1. å‡å°‘top_k
query_param = {"mode": "hybrid", "top_k": 5}

# 2. é™ä½MAX_IMAGES
MAX_IMAGES = 10

# 3. å¢åŠ vLLMçš„max_model_len
# åœ¨vLLMå¯åŠ¨å‘½ä»¤ä¸­æ·»åŠ  --max-model-len 65536
```

### é—®é¢˜3ï¼šæ£€ç´¢è´¨é‡å·®

**æ’æŸ¥æ­¥éª¤ï¼š**
```python
# 1. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦æ­£ç¡®ç´¢å¼•
# æŸ¥çœ‹working_dirä¸­çš„æ•°æ®åº“æ–‡ä»¶

# 2. æµ‹è¯•ä¸åŒquery mode
for mode in ["naive", "local", "global", "hybrid"]:
    result = await rag.aquery(query, mode=mode, only_need_context=True)
    print(f"\n{mode} mode results:\n{result[:500]}\n")

# 3. è°ƒæ•´embeddingå‡½æ•°
# ç¡®ä¿BGE-M3æ¨¡å‹æ­£ç¡®åŠ è½½
```

---

## ğŸ“š å»¶ä¼¸é˜…è¯»

- **RAG-Anythingæ–‡æ¡£**: äº†è§£æ›´å¤šé…ç½®é€‰é¡¹
- **LightRAGåŸç†**: ç†è§£åº•å±‚æ£€ç´¢æœºåˆ¶
- **Qwen2-VLæ–‡æ¡£**: ä¼˜åŒ–è§†è§‰ç†è§£æ•ˆæœ
- **vLLMè°ƒä¼˜æŒ‡å—**: æå‡æ¨ç†æ€§èƒ½

---

## âœ… æ€»ç»“

æ ¸å¿ƒä¿®å¤ï¼š
1. âœ… **ä¿ç•™RAGçš„system prompt** - è§£å†³referenceä¸¢å¤±
2. âœ… **ç§»é™¤é‡å¤çš„é—®é¢˜æ³¨å…¥** - è§£å†³æ··æ·†
3. âœ… **ç®€åŒ–visionå‡½æ•°é€»è¾‘** - æé«˜å¯ç»´æŠ¤æ€§
4. âœ… **å¢å¼ºè°ƒè¯•ä¿¡æ¯** - ä¾¿äºé—®é¢˜æ’æŸ¥
5. âœ… **ä¼˜åŒ–å‚æ•°é…ç½®** - æé«˜æ£€ç´¢è´¨é‡

è¿™äº›ä¿®å¤ç¡®ä¿äº†ï¼š
- Referenceç”Ÿæˆç¨³å®š
- å¹»è§‰æ˜¾è‘—å‡å°‘
- é€»è¾‘æ¸…æ™°ç®€æ´
- æ˜“äºè°ƒè¯•å’Œæ‰©å±•
